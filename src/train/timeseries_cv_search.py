# cross_validate_xgboost.py
import numpy as np
import xgboost as xgb
from sklearn.model_selection import TimeSeriesSplit
import itertools

def generate_param_combinations(param_grid_dict):
    keys = list(param_grid_dict.keys())
    values = list(param_grid_dict.values())
    combinations = [dict(zip(keys, combo)) for combo in itertools.product(*values)]
    return combinations

def cross_validate_xgboost_with_early_stopping(
    X, y,
    param_grid_dict,
    base_params=None,
    n_splits=5,
    metric='aucpr'
):
    tscv = TimeSeriesSplit(n_splits=n_splits)
    best_score = -np.inf
    best_params = None

    param_combinations = generate_param_combinations(param_grid_dict)
    print(f"\nâœ… å…±æœ‰ {len(param_combinations)} çµ„çµ„åˆè¦æ¸¬è©¦")

    for idx, params in enumerate(param_combinations):
        fold_scores = []
        skip_count = 0

        for fold_id, (train_idx, val_idx) in enumerate(tscv.split(X)):
            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

            # è‹¥é©—è­‰é›†ä¸­åªæœ‰å–®ä¸€é¡åˆ¥ï¼Œè·³é
            if len(np.unique(y_val)) < 2:
                print(f"âš ï¸ ç¬¬ {fold_id+1} fold é©—è­‰é›†åªæœ‰å–®ä¸€é¡åˆ¥ï¼Œå·²è·³é")
                skip_count += 1
                continue

            model = xgb.XGBClassifier(
                **(base_params or {}),
                **params
            )

            model.fit(
                X_train, y_train,
                eval_set=[(X_val, y_val)],
                # early_stopping_rounds=50,
                # eval_metric=metric,
                verbose=False
            )

            score = model.evals_result()['validation_0'][metric][-1]
            fold_scores.append(score)

        if skip_count == n_splits:
            print(f"âŒ æ‰€æœ‰ fold éƒ½ç„¡æ•ˆï¼šåƒæ•¸ {params} å…¨éƒ¨è·³é\n")
            continue

        avg_score = np.mean(fold_scores)
        print(f"[{idx+1}/{len(param_combinations)}] åƒæ•¸ {params} å¹³å‡ {metric}: {avg_score:.5f}")

        if avg_score > best_score:
            best_score = avg_score
            best_params = params

    if best_params is None:
        raise ValueError("âŒ ç„¡æœ‰æ•ˆçš„äº¤å‰é©—è­‰çµæœï¼Œç„¡æ³•ç”¢ç”Ÿæœ€ä½³åƒæ•¸ã€‚è«‹æª¢æŸ¥è³‡æ–™é †åºèˆ‡ SMOTE ä½¿ç”¨ã€‚")

    print(f"\nğŸ† æœ€ä½³åƒæ•¸: {best_params}ï¼Œå¹³å‡ {metric}: {best_score:.5f}")
    return best_params